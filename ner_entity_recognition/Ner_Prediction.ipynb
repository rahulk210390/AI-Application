{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d627860-cedb-425e-936f-af0f4dc79c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66d90b6f-4e59-4744-9c61-f6374a3f19e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'D:/NER_CaseStudy/ner_dataset.csv'\n",
    "df = pd.read_csv(file_path, encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb8d771e-453c-4bf3-9bb5-1819bc1d0c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5da52e16-ccee-4cd0-bc73-ccd354b2f57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAHUL\\AppData\\Local\\Temp\\ipykernel_5236\\2569526105.py:2: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['Sentence #'] = df['Sentence #'].fillna(method='ffill')\n",
      "C:\\Users\\RAHUL\\AppData\\Local\\Temp\\ipykernel_5236\\2569526105.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sentences = df.groupby('Sentence #').apply(lambda x: (x['Word'].tolist(), x['Tag'].tolist())).tolist()\n"
     ]
    }
   ],
   "source": [
    "# Fill forward the 'Sentence #' column to ensure every word has a sentence number\n",
    "df['Sentence #'] = df['Sentence #'].fillna(method='ffill')\n",
    "\n",
    "# Drop the POS column as it's not needed for this task\n",
    "df = df.drop(columns=['POS'])\n",
    "\n",
    "# Ensure that all 'Word' entries are strings\n",
    "df['Word'] = df['Word'].astype(str)\n",
    "\n",
    "# Group words and their tags by sentence number\n",
    "sentences = df.groupby('Sentence #').apply(lambda x: (x['Word'].tolist(), x['Tag'].tolist())).tolist()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e53a5037-2f20-4c27-9e8a-26f27db3a03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['Thousands',\n",
       "   'of',\n",
       "   'demonstrators',\n",
       "   'have',\n",
       "   'marched',\n",
       "   'through',\n",
       "   'London',\n",
       "   'to',\n",
       "   'protest',\n",
       "   'the',\n",
       "   'war',\n",
       "   'in',\n",
       "   'Iraq',\n",
       "   'and',\n",
       "   'demand',\n",
       "   'the',\n",
       "   'withdrawal',\n",
       "   'of',\n",
       "   'British',\n",
       "   'troops',\n",
       "   'from',\n",
       "   'that',\n",
       "   'country',\n",
       "   '.'],\n",
       "  ['O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-geo',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-geo',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-gpe',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O']),\n",
       " (['Iranian',\n",
       "   'officials',\n",
       "   'say',\n",
       "   'they',\n",
       "   'expect',\n",
       "   'to',\n",
       "   'get',\n",
       "   'access',\n",
       "   'to',\n",
       "   'sealed',\n",
       "   'sensitive',\n",
       "   'parts',\n",
       "   'of',\n",
       "   'the',\n",
       "   'plant',\n",
       "   'Wednesday',\n",
       "   ',',\n",
       "   'after',\n",
       "   'an',\n",
       "   'IAEA',\n",
       "   'surveillance',\n",
       "   'system',\n",
       "   'begins',\n",
       "   'functioning',\n",
       "   '.'],\n",
       "  ['B-gpe',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-tim',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-org',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O']),\n",
       " (['Helicopter',\n",
       "   'gunships',\n",
       "   'Saturday',\n",
       "   'pounded',\n",
       "   'militant',\n",
       "   'hideouts',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Orakzai',\n",
       "   'tribal',\n",
       "   'region',\n",
       "   ',',\n",
       "   'where',\n",
       "   'many',\n",
       "   'Taliban',\n",
       "   'militants',\n",
       "   'are',\n",
       "   'believed',\n",
       "   'to',\n",
       "   'have',\n",
       "   'fled',\n",
       "   'to',\n",
       "   'avoid',\n",
       "   'an',\n",
       "   'earlier',\n",
       "   'military',\n",
       "   'offensive',\n",
       "   'in',\n",
       "   'nearby',\n",
       "   'South',\n",
       "   'Waziristan',\n",
       "   '.'],\n",
       "  ['O',\n",
       "   'O',\n",
       "   'B-tim',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-geo',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-org',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-geo',\n",
       "   'I-geo',\n",
       "   'O'])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d278718-776c-48e3-8d28-0ce5e19afd8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28775, 9592, 9592)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_data, test_data = train_test_split(sentences, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2\n",
    "\n",
    "# Display the sizes of the splits\n",
    "len(train_data), len(val_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6217dd62-3e86-4126-96b6-1bbb61068cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sentence, index):\n",
    "    \"\"\"\n",
    "    Extract features for a given word in a sentence.\n",
    "\n",
    "    Parameters:\n",
    "    sentence (list of str): The list of words in the sentence.\n",
    "    index (int): The index of the word to extract features for.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary of features for the word.\n",
    "    \"\"\"\n",
    "    word = sentence[index]\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.casefold(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'word.isdigit()': word.isdecimal(),\n",
    "    }\n",
    "    if index > 0:\n",
    "        word1 = sentence[index - 1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.casefold(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True  # Beginning of Sentence\n",
    "\n",
    "    if index < len(sentence) - 1:\n",
    "        word1 = sentence[index + 1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.casefold(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True  # End of Sentence\n",
    "\n",
    "    return features\n",
    "\n",
    "def sentence2features(sentence):\n",
    "    \"\"\"\n",
    "    Extract features for all words in a sentence.\n",
    "\n",
    "    Parameters:\n",
    "    sentence (list of str): The list of words in the sentence.\n",
    "\n",
    "    Returns:\n",
    "    list of dict: A list of dictionaries containing features for each word.\n",
    "    \"\"\"\n",
    "    return [word2features(sentence, i) for i in range(len(sentence))]\n",
    "\n",
    "def sentence2labels(sentence_tags):\n",
    "    \"\"\"\n",
    "    Extract labels for all words in a sentence.\n",
    "\n",
    "    Parameters:\n",
    "    sentence_tags (list of str): The list of tags in the sentence.\n",
    "\n",
    "    Returns:\n",
    "    list of str: A list of tags.\n",
    "    \"\"\"\n",
    "    return sentence_tags\n",
    "\n",
    "def sentence2tokens(sentence):\n",
    "    \"\"\"\n",
    "    Extract tokens for all words in a sentence.\n",
    "\n",
    "    Parameters:\n",
    "    sentence (list of str): The list of words in the sentence.\n",
    "\n",
    "    Returns:\n",
    "    list of str: A list of words.\n",
    "    \"\"\"\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c9f4236-6e08-4433-a336-db67effbef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sentence2features(words) for words, tags in train_data]\n",
    "y_train = [sentence2labels(tags) for words, tags in train_data]\n",
    "\n",
    "X_val = [sentence2features(words) for words, tags in val_data]\n",
    "y_val = [sentence2labels(tags) for words, tags in val_data]\n",
    "\n",
    "X_test = [sentence2features(words) for words, tags in test_data]\n",
    "y_test = [sentence2labels(tags) for words, tags in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cb2e455-a926-4460-8fae-a06b2f67a291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn_crfsuite in c:\\users\\rahul\\anaconda3\\envs\\myenv\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: python-crfsuite>=0.9.7 in c:\\users\\rahul\\anaconda3\\envs\\myenv\\lib\\site-packages (from sklearn_crfsuite) (0.9.10)\n",
      "Requirement already satisfied: scikit-learn>=0.24.0 in c:\\users\\rahul\\anaconda3\\envs\\myenv\\lib\\site-packages (from sklearn_crfsuite) (1.5.1)\n",
      "Requirement already satisfied: tabulate>=0.4.2 in c:\\users\\rahul\\anaconda3\\envs\\myenv\\lib\\site-packages (from sklearn_crfsuite) (0.9.0)\n",
      "Requirement already satisfied: tqdm>=2.0 in c:\\users\\rahul\\anaconda3\\envs\\myenv\\lib\\site-packages (from sklearn_crfsuite) (4.66.4)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\rahul\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\rahul\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\rahul\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\rahul\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rahul\\anaconda3\\envs\\myenv\\lib\\site-packages (from tqdm>=2.0->sklearn_crfsuite) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn_crfsuite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ce65939-b672-4528-b1af-580f35f09683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import nltk\n",
    "import scipy\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite.metrics import flat_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad0d3a14-bfbf-4f8f-abc1-ea7cd6e0603d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.36      0.11      0.16        94\n",
      "       B-eve       0.51      0.29      0.37        70\n",
      "       B-geo       0.86      0.91      0.88      7558\n",
      "       B-gpe       0.96      0.93      0.95      3142\n",
      "       B-nat       0.46      0.33      0.38        40\n",
      "       B-org       0.80      0.71      0.75      4151\n",
      "       B-per       0.84      0.81      0.82      3400\n",
      "       B-tim       0.92      0.88      0.90      4077\n",
      "       I-art       0.23      0.07      0.11        84\n",
      "       I-eve       0.32      0.11      0.16        65\n",
      "       I-geo       0.81      0.79      0.80      1462\n",
      "       I-gpe       0.94      0.48      0.64        33\n",
      "       I-nat       0.50      0.15      0.24        13\n",
      "       I-org       0.80      0.78      0.79      3394\n",
      "       I-per       0.85      0.88      0.86      3406\n",
      "       I-tim       0.82      0.79      0.80      1251\n",
      "           O       0.99      0.99      0.99    177590\n",
      "\n",
      "    accuracy                           0.97    209830\n",
      "   macro avg       0.70      0.59      0.62    209830\n",
      "weighted avg       0.97      0.97      0.97    209830\n",
      "\n",
      "CPU times: total: 1min 36s\n",
      "Wall time: 1min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Step 4: Baseline model (CRF)\n",
    "crf = CRF(\n",
    "    algorithm='lbfgs', \n",
    "    c1=0.1, \n",
    "    c2=0.1, \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=False)\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the baseline model\n",
    "y_pred = crf.predict(X_test)\n",
    "print(flat_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bed20304-357f-4db2-af3a-75432298431e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-gpe',\n",
       " 'O',\n",
       " 'B-geo',\n",
       " 'B-tim',\n",
       " 'I-tim',\n",
       " 'I-geo',\n",
       " 'B-org',\n",
       " 'B-per',\n",
       " 'I-org',\n",
       " 'I-per',\n",
       " 'B-eve',\n",
       " 'I-eve',\n",
       " 'I-gpe',\n",
       " 'B-art',\n",
       " 'I-art',\n",
       " 'B-nat',\n",
       " 'I-nat']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52aadf7b-883c-4b5d-af23-5fce6cb4ba84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.17 s\n",
      "Wall time: 2.27 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9689074736708978"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn_crfsuite.metrics import flat_f1_score\n",
    "y_pred = crf.predict(X_test)\n",
    "flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde1f42e-a7f9-4451-a6de-8e73a5ee5e4b",
   "metadata": {},
   "source": [
    "The f1_score is dominated by O entities in tag. <br> Lets remove it and then calculate flat_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9822e380-7c5e-4fc7-b6eb-531c830372e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebec557e-28ae-475f-a227-103496c7eb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.08 s\n",
      "Wall time: 2.21 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8411981934787471"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = crf.predict(X_test)\n",
    "flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3781a2ad-7b7c-4b86-bad7-d540fd6c846f",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19b7c129-f1a2-4fcb-b075-bcffabc2a853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-gpe',\n",
       " 'B-geo',\n",
       " 'O',\n",
       " 'B-tim',\n",
       " 'I-tim',\n",
       " 'I-geo',\n",
       " 'B-org',\n",
       " 'B-per',\n",
       " 'I-org',\n",
       " 'I-per',\n",
       " 'B-eve',\n",
       " 'I-eve',\n",
       " 'I-gpe',\n",
       " 'B-art',\n",
       " 'I-art',\n",
       " 'B-nat',\n",
       " 'I-nat']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.insert(2, 'O')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6b0bf03-2e6d-4e06-acce-a62205e2cb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "CPU times: total: 7min 2s\n",
      "Wall time: 36min 1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=CRF(algorithm=&#x27;lbfgs&#x27;,\n",
       "                                 all_possible_transitions=True,\n",
       "                                 max_iterations=100),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={&#x27;c1&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000022504F35240&gt;,\n",
       "                                        &#x27;c2&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x00000225A6160430&gt;},\n",
       "                   scoring=make_scorer(flat_f1_score, response_method=&#x27;predict&#x27;, average=weighted, labels=[&#x27;B-gpe&#x27;, &#x27;B-geo&#x27;, &#x27;O&#x27;, &#x27;B-tim&#x27;, &#x27;I-tim&#x27;, &#x27;I-geo&#x27;, &#x27;B-org&#x27;, &#x27;B-per&#x27;, &#x27;I-org&#x27;, &#x27;I-per&#x27;, &#x27;B-eve&#x27;, &#x27;I-eve&#x27;, &#x27;I-gpe&#x27;, &#x27;B-art&#x27;, &#x27;I-art&#x27;, &#x27;B-nat&#x27;, &#x27;I-nat&#x27;]),\n",
       "                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=CRF(algorithm=&#x27;lbfgs&#x27;,\n",
       "                                 all_possible_transitions=True,\n",
       "                                 max_iterations=100),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={&#x27;c1&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000022504F35240&gt;,\n",
       "                                        &#x27;c2&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x00000225A6160430&gt;},\n",
       "                   scoring=make_scorer(flat_f1_score, response_method=&#x27;predict&#x27;, average=weighted, labels=[&#x27;B-gpe&#x27;, &#x27;B-geo&#x27;, &#x27;O&#x27;, &#x27;B-tim&#x27;, &#x27;I-tim&#x27;, &#x27;I-geo&#x27;, &#x27;B-org&#x27;, &#x27;B-per&#x27;, &#x27;I-org&#x27;, &#x27;I-per&#x27;, &#x27;B-eve&#x27;, &#x27;I-eve&#x27;, &#x27;I-gpe&#x27;, &#x27;B-art&#x27;, &#x27;I-art&#x27;, &#x27;B-nat&#x27;, &#x27;I-nat&#x27;]),\n",
       "                   verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: CRF</label><div class=\"sk-toggleable__content fitted\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=True, c1=0.1964049175254215,\n",
       "    c2=0.06373671076669477, max_iterations=100)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">CRF</label><div class=\"sk-toggleable__content fitted\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=True, c1=0.1964049175254215,\n",
       "    c2=0.06373671076669477, max_iterations=100)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=CRF(algorithm='lbfgs',\n",
       "                                 all_possible_transitions=True,\n",
       "                                 max_iterations=100),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'c1': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000022504F35240>,\n",
       "                                        'c2': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x00000225A6160430>},\n",
       "                   scoring=make_scorer(flat_f1_score, response_method='predict', average=weighted, labels=['B-gpe', 'B-geo', 'O', 'B-tim', 'I-tim', 'I-geo', 'B-org', 'B-per', 'I-org', 'I-per', 'B-eve', 'I-eve', 'I-gpe', 'B-art', 'I-art', 'B-nat', 'I-nat']),\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "import scipy.stats\n",
    "\n",
    "# define fixed parameters and parameters to search\n",
    "crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),             # Coefficient for L1 regularization\n",
    "    'c2': scipy.stats.expon(scale=0.05),            # Coefficient for L2 regularization\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(flat_f1_score,\n",
    "                        average='weighted', labels=labels)\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=50,\n",
    "                        scoring=f1_scorer)\n",
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05ad01f-9f61-492d-8fa4-c9b6a9647828",
   "metadata": {},
   "source": [
    "### Finding the best model paramter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82f755e1-9ab6-4c49-8367-27e3479e4563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'c1': 0.1964049175254215, 'c2': 0.06373671076669477}\n",
      "best CV score: 0.9676372423689402\n",
      "model size: 2.33M\n"
     ]
    }
   ],
   "source": [
    "# crf = rs.best_estimator_\n",
    "print('best params:', rs.best_params_)\n",
    "print('best CV score:', rs.best_score_)\n",
    "print('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa193b7f-40c8-492b-b861-c89b3eedf981",
   "metadata": {},
   "source": [
    "## Creating the model with best model paramter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4f56be4-8cfc-44ce-819c-eb6112d4d9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-gpe      0.964     0.931     0.947      3142\n",
      "       B-geo      0.857     0.909     0.882      7558\n",
      "           O      0.990     0.994     0.992    177590\n",
      "       B-tim      0.923     0.875     0.899      4077\n",
      "       I-tim      0.796     0.788     0.792      1251\n",
      "       I-geo      0.810     0.793     0.801      1462\n",
      "       B-org      0.797     0.711     0.751      4151\n",
      "       B-per      0.837     0.809     0.823      3400\n",
      "       I-org      0.798     0.784     0.791      3394\n",
      "       I-per      0.845     0.882     0.863      3406\n",
      "       B-eve      0.500     0.286     0.364        70\n",
      "       I-eve      0.304     0.108     0.159        65\n",
      "       I-gpe      0.895     0.515     0.654        33\n",
      "       B-art      0.312     0.106     0.159        94\n",
      "       I-art      0.207     0.071     0.106        84\n",
      "       B-nat      0.522     0.300     0.381        40\n",
      "       I-nat      0.500     0.154     0.235        13\n",
      "\n",
      "    accuracy                          0.969    209830\n",
      "   macro avg      0.697     0.589     0.623    209830\n",
      "weighted avg      0.969     0.969     0.969    209830\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crf = rs.best_estimator_\n",
    "y_pred = crf.predict(X_test)\n",
    "print(flat_classification_report(\n",
    "    y_test, y_pred, labels=labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1370381-64a2-45b2-80c1-29348cce7da8",
   "metadata": {},
   "source": [
    "`We can see there has been a significant surge in the precision of individual tags`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ee43c85-6b6d-4554-bee0-c23decff5445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Transition    Weight\n",
      "228  (B-nat, I-nat)  7.108852\n",
      "206  (B-art, I-art)  6.036389\n",
      "218  (I-art, I-art)  5.928776\n",
      "194  (I-gpe, I-gpe)  5.709978\n",
      "39   (B-geo, I-geo)  5.586272\n",
      "70   (I-tim, I-tim)  5.578686\n",
      "184  (I-eve, I-eve)  5.356160\n",
      "120  (B-per, I-per)  5.347107\n",
      "171  (B-eve, I-eve)  5.286099\n",
      "102  (B-org, I-org)  5.003399\n"
     ]
    }
   ],
   "source": [
    "# Prepare a list to store transitions and their scores\n",
    "from collections import Counter\n",
    "transitions = []\n",
    "\n",
    "trans_feature = Counter(crf.transition_features_)\n",
    "\n",
    "transitions_df = pd.DataFrame.from_dict(trans_feature, orient='index').reset_index()\n",
    "transitions_df = transitions_df.rename(columns={'index':'Transition', 0:'Weight'})\n",
    "# Sort transitions by score in descending order\n",
    "transitions_df = transitions_df.sort_values(by=\"Weight\", ascending=False)\n",
    "\n",
    "# Display the top 10 transitions\n",
    "top_n = 10\n",
    "print(transitions_df.head(top_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3bd4e5a3-fee1-4109-84f2-9cc169eb8ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Transition    Weight\n",
      "26       (O, I-per) -4.602011\n",
      "42   (B-geo, I-org) -4.660414\n",
      "8    (B-gpe, I-org) -4.692706\n",
      "134  (I-org, B-org) -4.918294\n",
      "0    (B-gpe, B-gpe) -4.960288\n",
      "152  (I-per, B-per) -5.763370\n",
      "25       (O, I-org) -6.148978\n",
      "21       (O, I-tim) -6.154378\n",
      "22       (O, I-geo) -6.431635\n",
      "118  (B-per, B-per) -9.729412\n"
     ]
    }
   ],
   "source": [
    "# Display the bottom 10 transitions\n",
    "botton_n = -10\n",
    "print(transitions_df.iloc[botton_n:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a09bb6-d630-494a-871c-3796cb7e2187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19a3c99b-47b3-4d22-9207-cae58a427fb8",
   "metadata": {},
   "source": [
    "## Test Model against custom  sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22e3fdb5-f4e0-4aa1-9f89-5ed0bc002c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(word):\n",
    "    # Define your feature extraction logic here\n",
    "    return {\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[:3]': word[:3],\n",
    "         'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3303002-230c-493e-af07-d7396b58ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert a sentence into features\n",
    "def sentence_to_features(sentence):\n",
    "    return [extract_features(word) for word in sentence]\n",
    "\n",
    "# Predict NER tags for the sentence\n",
    "def predict_tags(crf, sentence):\n",
    "    features = sentence_to_features(sentence)\n",
    "    return crf.predict([features])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e511b56-fa44-4a85-b020-7170f2b0fa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example sentence and true tags\n",
    "sentence = [\"John\", \"lives\", \"in\", \"New\", \"York\"]\n",
    "true_tags = [\"B-PER\", \"O\", \"O\", \"B-LOC\", \"I-LOC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfbbe101-517f-40cc-ba55-4d43e046b6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: John, True Tag: B-PER, Predicted Tag: B-geo\n",
      "Word: lives, True Tag: O, Predicted Tag: I-geo\n",
      "Word: in, True Tag: O, Predicted Tag: I-geo\n",
      "Word: New, True Tag: B-LOC, Predicted Tag: I-geo\n",
      "Word: York, True Tag: I-LOC, Predicted Tag: I-geo\n"
     ]
    }
   ],
   "source": [
    "# Get predicted tags\n",
    "predicted_tags = predict_tags(crf, sentence)\n",
    "\n",
    "# Print the results\n",
    "for word, true_tag, pred_tag in zip(sentence, true_tags, predicted_tags):\n",
    "    print(f\"Word: {word}, True Tag: {true_tag}, Predicted Tag: {pred_tag}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e99bb27f-6878-47f1-83e1-e328a61d3434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate accuracy\n",
    "correct_predictions = sum(t == p for t, p in zip(true_tags, predicted_tags))\n",
    "accuracy = correct_predictions / len(true_tags)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb06045-daee-447d-b024-ad3bf1338462",
   "metadata": {},
   "source": [
    "## Improved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d40a163-1bac-4536-ab39-26d08214533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizerFast\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import BertForTokenClassification, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from seqeval.metrics import classification_report\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e7ea57f-4cdb-4093-acca-c074456fc62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'D:/NER_CaseStudy/ner_dataset.csv'\n",
    "df = pd.read_csv(file_path, encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df3c23d9-3338-4b4a-86f8-8248544d98ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAHUL\\AppData\\Local\\Temp\\ipykernel_5236\\519715000.py:2: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['Sentence #'] = df['Sentence #'].fillna(method='ffill')\n",
      "C:\\Users\\RAHUL\\AppData\\Local\\Temp\\ipykernel_5236\\519715000.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sentences = df.groupby('Sentence #').apply(lambda s: [(w, t) for w, t in zip(s['Word'].values.tolist(), s['Tag'].values.tolist())])\n"
     ]
    }
   ],
   "source": [
    "# Fill forward the 'Sentence #' column to ensure every word has a sentence number\n",
    "df['Sentence #'] = df['Sentence #'].fillna(method='ffill')\n",
    "\n",
    "# Drop the POS column as it's not needed for this task\n",
    "df = df.drop(columns=['POS'])\n",
    "\n",
    "# Ensure that all 'Word' entries are strings\n",
    "df['Word'] = df['Word'].astype(str)\n",
    "\n",
    "# Group by sentence number and collect words and tags\n",
    "sentences = df.groupby('Sentence #').apply(lambda s: [(w, t) for w, t in zip(s['Word'].values.tolist(), s['Tag'].values.tolist())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d485becc-788a-4172-bcca-c08942e70adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28775, 9592, 9592)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training, validation, and test sets\n",
    "train_data, test_data = train_test_split(sentences, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2\n",
    "\n",
    "\n",
    "# Display the sizes of the splits\n",
    "len(train_data), len(val_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d59ea102-f1ac-4304-b6d3-fae63a69b438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and preserve labels\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37c508b3-9b02-4eef-9a2b-121de4d4d04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_preserve_labels(sentence, text_labels):\n",
    "    \"\"\"\n",
    "    Tokenize a sentence and preserve the word-level labels.\n",
    "\n",
    "    Parameters:\n",
    "    sentence (list of str): List of words in the sentence.\n",
    "    text_labels (list of str): List of labels corresponding to each word in the sentence.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Tokenized sentence and the corresponding labels.\n",
    "    \"\"\"\n",
    "    tokenized_sentence = []\n",
    "    labels = []\n",
    "\n",
    "    for word, label in zip(sentence, text_labels):\n",
    "        tokenized_word = tokenizer.tokenize(word)\n",
    "        n_subwords = len(tokenized_word)\n",
    "\n",
    "        tokenized_sentence.extend(tokenized_word)\n",
    "        labels.extend([label] * n_subwords)\n",
    "\n",
    "    return tokenized_sentence, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b21f4760-afce-4e92-bfdf-838ab2ff735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    \"\"\"\n",
    "    Preprocess the data by tokenizing and preserving labels.\n",
    "\n",
    "    Parameters:\n",
    "    data (list of list of tuples): List of sentences, where each sentence is a list of tuples (word, label).\n",
    "\n",
    "    Returns:\n",
    "    tuple: Encodings and labels for the tokenized data.\n",
    "    \"\"\"\n",
    "    tokenized_texts_and_labels = [tokenize_and_preserve_labels([word for word, label in sentence], [label for word, label in sentence]) for sentence in data]\n",
    "\n",
    "    tokenized_texts = [token_labels_pair[0] for token_labels_pair in tokenized_texts_and_labels]\n",
    "    labels = [token_labels_pair[1] for token_labels_pair in tokenized_texts_and_labels]\n",
    "\n",
    "    encodings = tokenizer(tokenized_texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)\n",
    "\n",
    "    return encodings, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f303308-3aa4-40e6-af10-1bf379b7a495",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_encodings, train_labels = preprocess_data(train_data)\n",
    "val_encodings, val_labels = preprocess_data(val_data)\n",
    "test_encodings, test_labels = preprocess_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f11f1ca-7ecb-4739-80cc-01955c1f7dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map tags to indices\n",
    "unique_tags = set(tag for doc in train_labels for tag in doc)\n",
    "# Returns: dict mapping each unique tag to an index.\n",
    "tag2idx = {tag: idx for idx, tag in enumerate(unique_tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54b2913d-e6db-495d-87f2-28b502add537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-art': 0,\n",
       " 'B-nat': 1,\n",
       " 'B-per': 2,\n",
       " 'B-org': 3,\n",
       " 'O': 4,\n",
       " 'I-geo': 5,\n",
       " 'B-tim': 6,\n",
       " 'B-geo': 7,\n",
       " 'I-tim': 8,\n",
       " 'I-eve': 9,\n",
       " 'B-gpe': 10,\n",
       " 'I-org': 11,\n",
       " 'I-per': 12,\n",
       " 'I-nat': 13,\n",
       " 'I-art': 14,\n",
       " 'I-gpe': 15,\n",
       " 'B-eve': 16}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d7287c7-0f15-41ba-bebc-c7baffa6c144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to tensor\n",
    "def encode_labels(labels, encodings):\n",
    "    \"\"\"\n",
    "    Encode labels to match the tokenized inputs.\n",
    "\n",
    "    Parameters:\n",
    "    labels (list of list of str): List of labels for each sentence.\n",
    "    encodings (dict): Encodings returned from the tokenizer.\n",
    "\n",
    "    Returns:\n",
    "    list of list of int: Encoded labels aligned with the tokenized inputs.\n",
    "    \"\"\"\n",
    "    encoded_labels = []\n",
    "    for doc_labels, doc_offset in zip(labels, encodings['offset_mapping']):\n",
    "        doc_enc_labels = np.ones(len(doc_offset), dtype=int) * -100\n",
    "        arr_offset = np.array(doc_offset)\n",
    "\n",
    "        doc_enc_labels[(arr_offset[:, 0] == 0) & (arr_offset[:, 1] != 0)] = [tag2idx[label] for label in doc_labels]\n",
    "\n",
    "        encoded_labels.append(doc_enc_labels.tolist())\n",
    "\n",
    "    return encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "97cd7300-11dc-4f3b-8da3-4fcd4a002c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_labels = encode_labels(train_labels, train_encodings)\n",
    "val_labels = encode_labels(val_labels, val_encodings)\n",
    "test_labels = encode_labels(test_labels, test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f6cdbaa8-2b57-4da0-8433-6b785b9e49a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Encoding to tensors\n",
    "train_encodings = {key: torch.tensor(val) for key, val in train_encodings.items()}\n",
    "val_encodings = {key: torch.tensor(val) for key, val in val_encodings.items()}\n",
    "test_encodings = {key: torch.tensor(val) for key, val in test_encodings.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe74f0db-bf8b-4182-9657-fab11325bd2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2169,  2021,  ...,     0,     0,     0],\n",
       "         [  101,  1109,  7640,  ...,     0,     0,     0],\n",
       "         [  101,  1262,  1375,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101,  1109, 20857,  ...,     0,     0,     0],\n",
       "         [  101,  1124,  1163,  ...,     0,     0,     0],\n",
       "         [  101,  1987,   119,  ...,     0,     0,     0]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'offset_mapping': tensor([[[0, 0],\n",
       "          [0, 7],\n",
       "          [0, 6],\n",
       "          ...,\n",
       "          [0, 0],\n",
       "          [0, 0],\n",
       "          [0, 0]],\n",
       " \n",
       "         [[0, 0],\n",
       "          [0, 3],\n",
       "          [0, 8],\n",
       "          ...,\n",
       "          [0, 0],\n",
       "          [0, 0],\n",
       "          [0, 0]],\n",
       " \n",
       "         [[0, 0],\n",
       "          [0, 3],\n",
       "          [0, 5],\n",
       "          ...,\n",
       "          [0, 0],\n",
       "          [0, 0],\n",
       "          [0, 0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0, 0],\n",
       "          [0, 3],\n",
       "          [0, 5],\n",
       "          ...,\n",
       "          [0, 0],\n",
       "          [0, 0],\n",
       "          [0, 0]],\n",
       " \n",
       "         [[0, 0],\n",
       "          [0, 2],\n",
       "          [0, 4],\n",
       "          ...,\n",
       "          [0, 0],\n",
       "          [0, 0],\n",
       "          [0, 0]],\n",
       " \n",
       "         [[0, 0],\n",
       "          [0, 2],\n",
       "          [0, 1],\n",
       "          ...,\n",
       "          [0, 0],\n",
       "          [0, 0],\n",
       "          [0, 0]]])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b9121dac-76fd-4b76-b4a3-69b7cc859b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert labels to tensors\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "val_labels = torch.tensor(val_labels)\n",
    "test_labels = torch.tensor(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2402cc04-440e-44e3-a350-bfce7fca7193",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], train_labels)\n",
    "val_dataset = TensorDataset(val_encodings['input_ids'], val_encodings['attention_mask'], val_labels)\n",
    "test_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "31ef5a6d-2762-4f41-bd3c-05054946e245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data loaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ace9c766-6385-40ca-b897-cb4ee1d06f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\RAHUL\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model\n",
    "model = BertForTokenClassification.from_pretrained('bert-base-cased', num_labels=len(tag2idx))\n",
    "# Training loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=3e-5, eps=1e-8)\n",
    "\n",
    "# Set up the learning rate scheduler\n",
    "epochs = 3\n",
    "total_steps = len(train_dataset) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a07b67c9-271c-498b-b894-43e8b2a64bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-07-21_20_08'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "curr_timestamp = datetime.now().strftime('%Y-%m-%d_%H_%M')\n",
    "curr_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b9e56ba0-81ea-4007-90f5-54862de71326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.getcwd()\n",
    "\n",
    "# Specify the directory on the D drive\n",
    "save_directory_model = 'D:\\\\NER_CaseStudy\\\\ner_model'+curr_timestamp\n",
    "save_directory_tokenizer = 'D:\\\\NER_CaseStudy\\\\tokenizer'+curr_timestamp\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(save_directory_model):\n",
    "    os.makedirs(save_directory_model)\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(save_directory_tokenizer):\n",
    "    os.makedirs(save_directory_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0c4ac68d-fc1e-4da3-ab26-eea2be8125ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Memory Usage:\n",
      "Allocated: 0.4 GB\n",
      "Cached:    0.4 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAHUL\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.1907845976658418\n",
      "Validation loss: 0.13717002308927476\n",
      "Average training loss: 0.11511767752625963\n",
      "Validation loss: 0.12744965537451208\n",
      "Average training loss: 0.08455044302153399\n",
      "Validation loss: 0.13398817390979578\n",
      "CPU times: total: 40min 49s\n",
      "Wall time: 1h 5min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Training loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "    \n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Move tensors to the GPU\n",
    "        b_input_ids = b_input_ids.to(device)\n",
    "        b_input_mask = b_input_mask.to(device)\n",
    "        b_labels = b_labels.to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Average training loss: {avg_train_loss}\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "\n",
    "    for batch in val_dataloader:\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Move tensors to the GPU\n",
    "        b_input_ids = b_input_ids.to(device)\n",
    "        b_input_mask = b_input_mask.to(device)\n",
    "        b_labels = b_labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "            loss = outputs.loss\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    print(f\"Validation loss: {avg_val_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "39ce35a7-a6a6-4b8c-b2ec-2ef215d01fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('D:\\\\NER_CaseStudy\\\\tokenizer2024-07-21_20_082024-07-21_20_08\\\\tokenizer_config.json',\n",
       " 'D:\\\\NER_CaseStudy\\\\tokenizer2024-07-21_20_082024-07-21_20_08\\\\special_tokens_map.json',\n",
       " 'D:\\\\NER_CaseStudy\\\\tokenizer2024-07-21_20_082024-07-21_20_08\\\\vocab.txt',\n",
       " 'D:\\\\NER_CaseStudy\\\\tokenizer2024-07-21_20_082024-07-21_20_08\\\\added_tokens.json',\n",
       " 'D:\\\\NER_CaseStudy\\\\tokenizer2024-07-21_20_082024-07-21_20_08\\\\tokenizer.json')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save_pretrained(save_directory_model+curr_timestamp)\n",
    "tokenizer.save_pretrained(save_directory_tokenizer+curr_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0958868b-6858-45a4-8078-9c8a6a4fd042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'B-art',\n",
       " 1: 'B-nat',\n",
       " 2: 'B-per',\n",
       " 3: 'B-org',\n",
       " 4: 'O',\n",
       " 5: 'I-geo',\n",
       " 6: 'B-tim',\n",
       " 7: 'B-geo',\n",
       " 8: 'I-tim',\n",
       " 9: 'I-eve',\n",
       " 10: 'B-gpe',\n",
       " 11: 'I-org',\n",
       " 12: 'I-per',\n",
       " 13: 'I-nat',\n",
       " 14: 'I-art',\n",
       " 15: 'I-gpe',\n",
       " 16: 'B-eve'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2tag = {idx: tag for tag, idx in tag2idx.items()}\n",
    "idx2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b6ee1539-496b-4aa2-a656-573842013c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         art       0.12      0.04      0.06       166\n",
      "         eve       0.39      0.26      0.31        80\n",
      "         geo       0.84      0.90      0.87     12109\n",
      "         gpe       0.95      0.92      0.94      3525\n",
      "         nat       0.47      0.15      0.23        59\n",
      "         org       0.75      0.70      0.72      7295\n",
      "         per       0.78      0.81      0.79      5579\n",
      "         tim       0.86      0.85      0.85      4460\n",
      "\n",
      "   micro avg       0.82      0.83      0.83     33273\n",
      "   macro avg       0.65      0.58      0.60     33273\n",
      "weighted avg       0.82      0.83      0.82     33273\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Move tensors to the appropriate device\n",
    "        b_input_ids = b_input_ids.to(device)\n",
    "        b_input_mask = b_input_mask.to(device)\n",
    "        b_labels = b_labels.to(device)\n",
    "\n",
    "        # Get model outputs\n",
    "        outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
    "        logits = outputs.logits\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        for i in range(len(label_ids)):\n",
    "            pred_tags = []\n",
    "            true_tags = []\n",
    "            for j in range(len(label_ids[i])):\n",
    "                if label_ids[i][j] != -100:\n",
    "                    pred_tag_idx = np.argmax(logits[i][j])\n",
    "                    pred_tags.append(idx2tag[pred_tag_idx])\n",
    "                    true_tags.append(idx2tag[label_ids[i][j]])\n",
    "\n",
    "            predictions.append(pred_tags)\n",
    "            true_labels.append(true_tags)\n",
    "\n",
    "print(classification_report(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6f5d0eae-4f26-4dda-93a3-1303d8f7eda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  ['John', 'lives', 'in', 'New', 'York']\n",
      "Predicted Tags:  ['B-nat', 'I-per', 'I-tim', 'I-gpe', 'I-tim', 'O', 'I-geo']\n",
      "True Tags:  ['B-PER', 'O', 'O', 'B-LOC', 'I-LOC']\n"
     ]
    }
   ],
   "source": [
    "# Example sentence and true tags\n",
    "sentence = [\"John\", \"lives\", \"in\", \"New\", \"York\"]\n",
    "true_tags = [\"B-PER\", \"O\", \"O\", \"B-LOC\", \"I-LOC\"]\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')\n",
    "model = BertForTokenClassification.from_pretrained('bert-base-cased', num_labels=len(tag2idx))\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Tokenize the input sentence\n",
    "tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, true_tags)\n",
    "\n",
    "# Convert the tokenized sentence to input IDs and attention masks\n",
    "inputs = tokenizer(tokenized_sentence, is_split_into_words=True, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# Move tensors to the GPU if available\n",
    "input_ids = inputs[\"input_ids\"].to(device)\n",
    "attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "\n",
    "# Make predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=2)\n",
    "\n",
    "# Convert predictions and true labels back to their respective tag names\n",
    "predictions = predictions.cpu().numpy().flatten()\n",
    "predicted_tags = [idx2tag[pred] for pred in predictions if pred != -100]\n",
    "\n",
    "# Output the predicted tags\n",
    "print(\"Sentence: \", sentence)\n",
    "print(\"Predicted Tags: \", predicted_tags)\n",
    "print(\"True Tags: \", true_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb275880-bc72-431b-8b5c-162998b52fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
